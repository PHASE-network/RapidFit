
Step 1)

Make your data file(s) > 10M available on the GRID		See:		Upload_Files_to_GRID_README

Step 2)

edit your XML to request only the filename as the data files will be downloaded to the working directory on the grid machine for running over


Step 3)

Edit 2DLL_Scan_From_XML.py
				you need to make sure the RapidFit_Path points to the ROOT of your RapidFit svn checkout

Step 4)

Customise the parameters in 2DLL_Scan_From_XML.py

X_par="Phi_s"
Y_par="deltaGamma"

X_min=-2.
X_max=0.
Y_min=-0.1
Y_max=0.2

resolution=40
sqrt_jobs_per_core=4			//	sqrt( number of grid points per CPU ) so this runs 16 points per CPU


Step 5)

Run the script as:
			SetupProject Ganga

			ganga 2DLL_Scan_From_XML.py Your_XML_FILE.xml  LFN:/lhcb/user/r/rcurrie/Pass3-version2_Bs_310711_RapidFit.root optional_background.root optional_acceptance.txt

The XML you want to run over has to be the second argument to ganga (and the first argument passed to the script)

Any and ALL LFNs in the argument list are added to the jobs inputsandbox and are set to be downloaded into the working directory for when the job starts running

Any further arguments are treated as input files that should be added to the inputsandbox (this must be < 10M but you shouldn't have to worry for background and acceptance input files)



Step 6)

Chose option 1 and send the job to the grid









Steps 7 onward are optional but are how I deal with the output data from these jobs)


I have many scans broken into lots of subjobs so I enable the parameter in my $HOME/.gagarc to stop ganga polling DIRACC

autostart = False



Step 7)

Make note of the ganga job number from Step 6

edit GetDiracJobIDFromGanga.py to have the same jobnumber as the job from Step 6

run:		ganga GetDiracJobIDFromGanga.py

this will create a new .log file with the Dirac JobID associated with each subjob of the ganga job



Step 8)

Run GetDiracOutput.py:

				Setup LHCbDirac
				python GetDiracOutput.py $PWD/jobnum.log /tmp/$USER/some_path

(You need to pass the full path to the .log file)


this downloads both the outputData and outputSandbox from all jobs in the jobnum.log file

To download the output from 10 subjobs at a time:

				python GetDiracOutput.py $PWD/jobnum.log /tmp/$USER/some_path & python GetDiracOutput.py $PWD/jobnum.log /tmp/$USER/some_path & python GetDiracOutput.py $PWD/jobnum.log /tmp/$USER/some_path & python GetDiracOutput.py $PWD/jobnum.log /tmp/$USER/some_path & ...


running multiple download requests at a time is MUCH faster than ganga


Step 9)

		Plot and enjoy the output of your jobs

